#####################################################################
Job ID: 1401676
Job Name: MF_MNIST_MLP_s8
Running on host: t0022
Executing command in: /net/tscratch/people/plgspyra/BeyondBackpropagation
Using config file: configs/mf/mnist_mlp_2x1000.yaml
Allocated GPU: 0
#####################################################################
Derived Experiment Name: mnist_mlp_2x1000
Loading modules...
Modules loaded:
Activating virtual environment...
Checking PyTorch CUDA...
PyTorch version: 2.4.0+cu121
CUDA available: True
CUDA version: 12.1
cuDNN version: 90100
Running the experiment script...
Loading and merging configuration from: configs/mf/mnist_mlp_2x1000.yaml
Configuration loaded and merged successfully:
{'algorithm': {'name': 'MF'},
 'algorithm_params': {'epochs_per_layer': 14,
                      'log_interval': 9999,
                      'lr': 0.001570297088405539,
                      'mf_early_stopping_enabled': True,
                      'mf_early_stopping_min_delta': 0.0001,
                      'mf_early_stopping_patience': 5,
                      'optimizer_type': 'Adam',
                      'weight_decay': 0.0},
 'carbon_tracker': {'country_iso_code': 'POL',
                    'enabled': True,
                    'mode': 'offline',
                    'output_dir': 'results/carbon'},
 'checkpointing': {'checkpoint_dir': 'checkpoints/mf_mnist_mlp_2x1000',
                   'save_best_metric': 'bp_val_accuracy'},
 'data': {'download': True,
          'image_size': 28,
          'input_channels': 1,
          'name': 'MNIST',
          'num_classes': 10,
          'root': './data',
          'val_split': 0.1},
 'data_loader': {'batch_size': 128, 'num_workers': 4, 'pin_memory': True},
 'experiment_name': 'mf_mnist_mlp_2x1000',
 'general': {'device': 'auto', 'seed': 42},
 'logging': {'level': 'INFO',
             'wandb': {'entity': 'przspyra11',
                       'project': 'BeyondBackpropagation',
                       'use_wandb': True}},
 'model': {'name': 'MF_MLP',
           'params': {'activation': 'ReLU',
                      'bias': True,
                      'hidden_dims': [1000, 1000]}},
 'monitoring': {'enabled': True,
                'energy_enabled': True,
                'energy_interval_sec': 0.2},
 'optimizer': {'lr': 0.001, 'type': 'AdamW', 'weight_decay': 0.0001},
 'profiling': {'enabled': True, 'verbose': False},
 'training': {'criterion': 'CrossEntropyLoss',
              'early_stopping_enabled': True,
              'early_stopping_metric': 'bp_val_loss',
              'early_stopping_min_delta': 0.0,
              'early_stopping_mode': 'min',
              'early_stopping_patience': 20,
              'epochs': 100,
              'log_interval': 100},
 'tuning': {'direction': 'maximize',
            'enabled': False,
            'lr_range': [1e-05, 0.01],
            'metric': 'val_accuracy',
            'n_trials': 50,
            'pruner': 'Median',
            'sampler': 'TPE',
            'wd_range': [1e-06, 0.001]}}
2025-05-08 04:07:39,672 - root - INFO - Logging to file: results/mf_mnist_mlp_2x1000/mf_mnist_mlp_2x1000_run.log
2025-05-08 04:07:39,672 - root - INFO - Root logger setup complete. Level: INFO
2025-05-08 04:07:39,673 - src.utils.logging_utils - INFO - 
--- Starting Experiment ---
2025-05-08 04:07:39,673 - src.utils.logging_utils - INFO - Found EXPERIMENT_SEED environment variable: 49. Overriding config seed (42).
2025-05-08 04:07:39,753 - src.utils.helpers - INFO - Set random seed to 49 (including CUDA)
2025-05-08 04:07:39,753 - src.utils.logging_utils - INFO - Using random seed: 49
2025-05-08 04:07:39,753 - src.utils.logging_utils - INFO - Using device: cuda (Preference: 'auto')
2025-05-08 04:07:41,013 - src.utils.logging_utils - INFO - Weights & Biases run initialized: https://wandb.ai/przspyra11/BeyondBackpropagation/runs/t81gm1zu
2025-05-08 04:07:41,018 - src.utils.monitoring - INFO - NVML initialized successfully.
2025-05-08 04:07:41,019 - src.utils.monitoring - INFO - NVIDIA Driver Version: 570.86.15
2025-05-08 04:07:41,019 - src.utils.monitoring - INFO - NVML version query (nvmlSystemGetNvmlVersion) not available in this pynvml library version.
2025-05-08 04:07:41,026 - src.utils.logging_utils - INFO - NVML active for GPU 0.
2025-05-08 04:07:41,026 - src.utils.logging_utils - INFO - Initial GPU Mem: 336.62 MiB Used / 40960.00 MiB Total
2025-05-08 04:07:41,026 - src.utils.logging_utils - INFO - GPU Energy monitor initialized (Interval: 0.2s).
2025-05-08 04:07:41,026 - src.utils.codecarbon_utils - INFO - Initializing CodeCarbon OfflineEmissionsTracker. Outputting to results/carbon/mf_mnist_mlp_2x1000_carbon.csv
2025-05-08 04:07:41,816 - src.utils.codecarbon_utils - INFO - CodeCarbon tracker started.
2025-05-08 04:07:41,818 - src.data_utils.datasets - INFO - Loading dataset: MNIST from ./data
2025-05-08 04:07:41,863 - src.data_utils.datasets - INFO - Applying specific MNIST fixed split: 50k train / 10k validation.
2025-05-08 04:07:41,865 - src.data_utils.datasets - INFO - Created fixed MNIST split: 50000 train / 10000 validation samples.
2025-05-08 04:07:41,866 - src.data_utils.datasets - INFO - DataLoaders created: Train (390 batches, 50000 samples), Validation (40 batches, 10000 samples), Test (40 batches, 10000 samples)
2025-05-08 04:07:41,866 - src.utils.logging_utils - INFO - Dataloaders created.
2025-05-08 04:07:41,866 - src.utils.logging_utils - INFO - Getting architecture: mf_mlp (Algo: MF)
2025-05-08 04:07:41,884 - src.architectures.mf_mlp - INFO - Initialized MF_MLP with 2 hidden layers.
2025-05-08 04:07:41,886 - src.architectures.mf_mlp - INFO - Feedforward Layer dimensions (W): 784 -> 1000 -> 1000 -> 10
2025-05-08 04:07:41,886 - src.architectures.mf_mlp - INFO - Created 3 projection matrices (M_0 to M_2).
2025-05-08 04:07:41,886 - src.utils.logging_utils - INFO - Model 'MF_MLP' (Algo: MF) created.
2025-05-08 04:07:41,993 - src.utils.logging_utils - INFO - Model 'MF_MLP' on cuda.
2025-05-08 04:07:41,994 - src.utils.logging_utils - INFO - Model trainable parameters: 1,823,850
2025-05-08 04:07:41,995 - src.utils.logging_utils - INFO - Model total parameters: 1,823,850
2025-05-08 04:07:42,622 - src.utils.logging_utils - INFO - Profiling FLOPs...
2025-05-08 04:07:42,675 - src.utils.profiling - INFO - Estimated Total Forward Pass FLOPs (via torch.profiler): 0.0036 GFLOPs
2025-05-08 04:07:42,676 - src.utils.logging_utils - INFO - Estimated Forward Pass GFLOPs: 0.0036 G
2025-05-08 04:07:42,677 - src.utils.logging_utils - INFO - Algorithm 'mf' is BP-free, Est. BP Update GFLOPs is N/A.
2025-05-08 04:07:42,677 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:42,677 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 0) ---
2025-05-08 04:07:42,677 - src.utils.logging_utils - INFO -   initial_gpu_mem_used_mib: 336.6250
2025-05-08 04:07:42,677 - src.utils.logging_utils - INFO -   codecarbon_enabled: True
2025-05-08 04:07:42,677 - src.utils.logging_utils - INFO -   codecarbon_mode: offline
2025-05-08 04:07:42,678 - src.utils.logging_utils - INFO -   codecarbon_country_iso: POL
2025-05-08 04:07:42,678 - src.utils.logging_utils - INFO -   model_parameters_trainable: 1823850
2025-05-08 04:07:42,678 - src.utils.logging_utils - INFO -   model_parameters_total: 1823850
2025-05-08 04:07:42,678 - src.utils.logging_utils - INFO -   estimated_fwd_gflops: 0.0036
2025-05-08 04:07:42,678 - src.utils.logging_utils - INFO -   estimated_bp_update_gflops: nan
2025-05-08 04:07:42,678 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:42,678 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:42,679 - src.utils.logging_utils - INFO - Starting training phase...
2025-05-08 04:07:42,679 - src.utils.monitoring - INFO - Started energy monitoring for GPU 0 (interval: 0.2s).
2025-05-08 04:07:42,679 - src.algorithms.mf - INFO - Starting layer-wise MF training for MLP with 2 W-layers and 3 M-matrices.
2025-05-08 04:07:42,694 - src.algorithms.mf - INFO - --- Starting MF training for Layer_W1_M1 ---
2025-05-08 04:07:44,612 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:44,614 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 390) ---
2025-05-08 04:07:44,614 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_Batch: 0.1046
2025-05-08 04:07:44,614 - src.utils.logging_utils - INFO -   Layer_W1_M1/GPU_Mem_Used_MiB_Batch: 908.0000
2025-05-08 04:07:44,614 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:44,614 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:44,615 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 1/14 - Train Loss: 0.211367, Peak Mem: 908.0 MiB
2025-05-08 04:07:44,615 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:44,615 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 390) ---
2025-05-08 04:07:44,615 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_EpochAvg: 0.2114
2025-05-08 04:07:44,615 - src.utils.logging_utils - INFO -   Layer_W1_M1/Peak_GPU_Mem_Epoch_MiB: 908.0000
2025-05-08 04:07:44,615 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:44,616 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:45,065 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 1/14 - Val Local Loss: 0.130849
2025-05-08 04:07:45,066 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:45,066 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 390) ---
2025-05-08 04:07:45,066 - src.utils.logging_utils - INFO -   Layer_W1_M1/Val_LocalLoss_Epoch: 0.1308
2025-05-08 04:07:45,066 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:45,066 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:46,967 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:46,968 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 780) ---
2025-05-08 04:07:46,969 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_Batch: 0.1018
2025-05-08 04:07:46,969 - src.utils.logging_utils - INFO -   Layer_W1_M1/GPU_Mem_Used_MiB_Batch: 912.0000
2025-05-08 04:07:46,969 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:46,969 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:46,970 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 2/14 - Train Loss: 0.083155, Peak Mem: 912.0 MiB
2025-05-08 04:07:46,970 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:46,970 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 780) ---
2025-05-08 04:07:46,970 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_EpochAvg: 0.0832
2025-05-08 04:07:46,970 - src.utils.logging_utils - INFO -   Layer_W1_M1/Peak_GPU_Mem_Epoch_MiB: 912.0000
2025-05-08 04:07:46,971 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:46,971 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:47,345 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 2/14 - Val Local Loss: 0.086997
2025-05-08 04:07:47,347 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:47,347 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 780) ---
2025-05-08 04:07:47,347 - src.utils.logging_utils - INFO -   Layer_W1_M1/Val_LocalLoss_Epoch: 0.0870
2025-05-08 04:07:47,347 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:47,347 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:49,245 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:49,247 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 1170) ---
2025-05-08 04:07:49,247 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_Batch: 0.0519
2025-05-08 04:07:49,247 - src.utils.logging_utils - INFO -   Layer_W1_M1/GPU_Mem_Used_MiB_Batch: 912.0000
2025-05-08 04:07:49,247 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:49,247 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:49,248 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 3/14 - Train Loss: 0.055759, Peak Mem: 912.0 MiB
2025-05-08 04:07:49,248 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:49,248 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 1170) ---
2025-05-08 04:07:49,248 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_EpochAvg: 0.0558
2025-05-08 04:07:49,248 - src.utils.logging_utils - INFO -   Layer_W1_M1/Peak_GPU_Mem_Epoch_MiB: 912.0000
2025-05-08 04:07:49,248 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:49,249 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:49,622 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 3/14 - Val Local Loss: 0.093721
2025-05-08 04:07:49,624 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:49,624 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 1170) ---
2025-05-08 04:07:49,624 - src.utils.logging_utils - INFO -   Layer_W1_M1/Val_LocalLoss_Epoch: 0.0937
2025-05-08 04:07:49,624 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:49,624 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:51,533 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:51,534 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 1560) ---
2025-05-08 04:07:51,534 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_Batch: 0.0471
2025-05-08 04:07:51,534 - src.utils.logging_utils - INFO -   Layer_W1_M1/GPU_Mem_Used_MiB_Batch: 912.0000
2025-05-08 04:07:51,534 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:51,535 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:51,535 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 4/14 - Train Loss: 0.039680, Peak Mem: 912.0 MiB
2025-05-08 04:07:51,536 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:51,536 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 1560) ---
2025-05-08 04:07:51,536 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_EpochAvg: 0.0397
2025-05-08 04:07:51,536 - src.utils.logging_utils - INFO -   Layer_W1_M1/Peak_GPU_Mem_Epoch_MiB: 912.0000
2025-05-08 04:07:51,536 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:51,536 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:51,910 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 4/14 - Val Local Loss: 0.082734
2025-05-08 04:07:51,911 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:51,911 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 1560) ---
2025-05-08 04:07:51,911 - src.utils.logging_utils - INFO -   Layer_W1_M1/Val_LocalLoss_Epoch: 0.0827
2025-05-08 04:07:51,911 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:51,911 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:53,827 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:53,829 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 1950) ---
2025-05-08 04:07:53,829 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_Batch: 0.0984
2025-05-08 04:07:53,829 - src.utils.logging_utils - INFO -   Layer_W1_M1/GPU_Mem_Used_MiB_Batch: 912.0000
2025-05-08 04:07:53,829 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:53,829 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:53,830 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 5/14 - Train Loss: 0.033635, Peak Mem: 912.0 MiB
2025-05-08 04:07:53,830 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:53,830 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 1950) ---
2025-05-08 04:07:53,830 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_EpochAvg: 0.0336
2025-05-08 04:07:53,830 - src.utils.logging_utils - INFO -   Layer_W1_M1/Peak_GPU_Mem_Epoch_MiB: 912.0000
2025-05-08 04:07:53,830 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:53,830 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:54,228 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 5/14 - Val Local Loss: 0.099222
2025-05-08 04:07:54,229 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:54,229 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 1950) ---
2025-05-08 04:07:54,229 - src.utils.logging_utils - INFO -   Layer_W1_M1/Val_LocalLoss_Epoch: 0.0992
2025-05-08 04:07:54,229 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:54,229 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:56,113 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:56,114 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 2340) ---
2025-05-08 04:07:56,114 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_Batch: 0.0124
2025-05-08 04:07:56,115 - src.utils.logging_utils - INFO -   Layer_W1_M1/GPU_Mem_Used_MiB_Batch: 914.0000
2025-05-08 04:07:56,115 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:56,115 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:56,116 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 6/14 - Train Loss: 0.027582, Peak Mem: 914.0 MiB
2025-05-08 04:07:56,116 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:56,116 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 2340) ---
2025-05-08 04:07:56,116 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_EpochAvg: 0.0276
2025-05-08 04:07:56,116 - src.utils.logging_utils - INFO -   Layer_W1_M1/Peak_GPU_Mem_Epoch_MiB: 914.0000
2025-05-08 04:07:56,116 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:56,116 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:56,502 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 6/14 - Val Local Loss: 0.098043
2025-05-08 04:07:56,503 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:56,503 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 2340) ---
2025-05-08 04:07:56,503 - src.utils.logging_utils - INFO -   Layer_W1_M1/Val_LocalLoss_Epoch: 0.0980
2025-05-08 04:07:56,503 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:56,503 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:58,394 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:58,395 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 2730) ---
2025-05-08 04:07:58,395 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_Batch: 0.1217
2025-05-08 04:07:58,395 - src.utils.logging_utils - INFO -   Layer_W1_M1/GPU_Mem_Used_MiB_Batch: 914.0000
2025-05-08 04:07:58,395 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:58,395 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:58,396 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 7/14 - Train Loss: 0.023339, Peak Mem: 914.0 MiB
2025-05-08 04:07:58,396 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:58,396 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 2730) ---
2025-05-08 04:07:58,397 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_EpochAvg: 0.0233
2025-05-08 04:07:58,397 - src.utils.logging_utils - INFO -   Layer_W1_M1/Peak_GPU_Mem_Epoch_MiB: 914.0000
2025-05-08 04:07:58,397 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:58,397 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:58,774 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 7/14 - Val Local Loss: 0.097758
2025-05-08 04:07:58,774 - src.utils.logging_utils - INFO - 
2025-05-08 04:07:58,774 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 2730) ---
2025-05-08 04:07:58,774 - src.utils.logging_utils - INFO -   Layer_W1_M1/Val_LocalLoss_Epoch: 0.0978
2025-05-08 04:07:58,774 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:07:58,774 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:00,665 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:00,667 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 3120) ---
2025-05-08 04:08:00,667 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_Batch: 0.0865
2025-05-08 04:08:00,667 - src.utils.logging_utils - INFO -   Layer_W1_M1/GPU_Mem_Used_MiB_Batch: 914.0000
2025-05-08 04:08:00,667 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:00,667 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:00,668 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 8/14 - Train Loss: 0.024978, Peak Mem: 914.0 MiB
2025-05-08 04:08:00,668 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:00,668 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 3120) ---
2025-05-08 04:08:00,668 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_EpochAvg: 0.0250
2025-05-08 04:08:00,668 - src.utils.logging_utils - INFO -   Layer_W1_M1/Peak_GPU_Mem_Epoch_MiB: 914.0000
2025-05-08 04:08:00,669 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:00,669 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:01,050 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 8/14 - Val Local Loss: 0.100102
2025-05-08 04:08:01,050 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:01,050 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 3120) ---
2025-05-08 04:08:01,050 - src.utils.logging_utils - INFO -   Layer_W1_M1/Val_LocalLoss_Epoch: 0.1001
2025-05-08 04:08:01,050 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:01,050 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:02,950 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:02,952 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 3510) ---
2025-05-08 04:08:02,952 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_Batch: 0.0307
2025-05-08 04:08:02,952 - src.utils.logging_utils - INFO -   Layer_W1_M1/GPU_Mem_Used_MiB_Batch: 914.0000
2025-05-08 04:08:02,952 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:02,952 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:02,953 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 9/14 - Train Loss: 0.015714, Peak Mem: 914.0 MiB
2025-05-08 04:08:02,953 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:02,953 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 3510) ---
2025-05-08 04:08:02,953 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_EpochAvg: 0.0157
2025-05-08 04:08:02,953 - src.utils.logging_utils - INFO -   Layer_W1_M1/Peak_GPU_Mem_Epoch_MiB: 914.0000
2025-05-08 04:08:02,953 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:02,953 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:03,333 - src.algorithms.mf - INFO - Layer_W1_M1 Epoch 9/14 - Val Local Loss: 0.108859
2025-05-08 04:08:03,334 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:03,334 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 3510) ---
2025-05-08 04:08:03,334 - src.utils.logging_utils - INFO -   Layer_W1_M1/Val_LocalLoss_Epoch: 0.1089
2025-05-08 04:08:03,334 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:03,334 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:03,334 - src.algorithms.mf - INFO - --- Layer_W1_M1: Early Stopping Triggered at Epoch 9! ---
2025-05-08 04:08:03,335 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:03,335 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 3510) ---
2025-05-08 04:08:03,335 - src.utils.logging_utils - INFO -   Layer_W1_M1/Train_Loss_LayerAvg: 0.0157
2025-05-08 04:08:03,335 - src.utils.logging_utils - INFO -   Layer_W1_M1/Peak_GPU_Mem_Layer_MiB: 914.0000
2025-05-08 04:08:03,335 - src.utils.logging_utils - INFO -   Layer_W1_M1/Epochs_Trained: 9
2025-05-08 04:08:03,335 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:03,335 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:03,349 - src.algorithms.mf - INFO - --- Starting MF training for Layer_W2_M2 ---
2025-05-08 04:08:05,222 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:05,223 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 3900) ---
2025-05-08 04:08:05,223 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_Batch: 0.0529
2025-05-08 04:08:05,223 - src.utils.logging_utils - INFO -   Layer_W2_M2/GPU_Mem_Used_MiB_Batch: 934.0000
2025-05-08 04:08:05,223 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:05,224 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:05,224 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 1/14 - Train Loss: 0.053206, Peak Mem: 934.0 MiB
2025-05-08 04:08:05,225 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:05,225 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 3900) ---
2025-05-08 04:08:05,225 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_EpochAvg: 0.0532
2025-05-08 04:08:05,225 - src.utils.logging_utils - INFO -   Layer_W2_M2/Peak_GPU_Mem_Epoch_MiB: 934.0000
2025-05-08 04:08:05,225 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:05,225 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:05,603 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 1/14 - Val Local Loss: 0.107090
2025-05-08 04:08:05,604 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:05,604 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 3900) ---
2025-05-08 04:08:05,604 - src.utils.logging_utils - INFO -   Layer_W2_M2/Val_LocalLoss_Epoch: 0.1071
2025-05-08 04:08:05,604 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:05,604 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:07,536 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:07,538 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 4290) ---
2025-05-08 04:08:07,538 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_Batch: 0.0030
2025-05-08 04:08:07,538 - src.utils.logging_utils - INFO -   Layer_W2_M2/GPU_Mem_Used_MiB_Batch: 934.0000
2025-05-08 04:08:07,538 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:07,538 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:07,539 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 2/14 - Train Loss: 0.017699, Peak Mem: 934.0 MiB
2025-05-08 04:08:07,539 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:07,539 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 4290) ---
2025-05-08 04:08:07,539 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_EpochAvg: 0.0177
2025-05-08 04:08:07,539 - src.utils.logging_utils - INFO -   Layer_W2_M2/Peak_GPU_Mem_Epoch_MiB: 934.0000
2025-05-08 04:08:07,539 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:07,540 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:07,913 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 2/14 - Val Local Loss: 0.148956
2025-05-08 04:08:07,914 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:07,914 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 4290) ---
2025-05-08 04:08:07,914 - src.utils.logging_utils - INFO -   Layer_W2_M2/Val_LocalLoss_Epoch: 0.1490
2025-05-08 04:08:07,914 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:07,914 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:09,840 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:09,842 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 4680) ---
2025-05-08 04:08:09,842 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_Batch: 0.000532
2025-05-08 04:08:09,842 - src.utils.logging_utils - INFO -   Layer_W2_M2/GPU_Mem_Used_MiB_Batch: 934.0000
2025-05-08 04:08:09,842 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:09,842 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:09,843 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 3/14 - Train Loss: 0.011065, Peak Mem: 934.0 MiB
2025-05-08 04:08:09,843 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:09,843 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 4680) ---
2025-05-08 04:08:09,844 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_EpochAvg: 0.0111
2025-05-08 04:08:09,844 - src.utils.logging_utils - INFO -   Layer_W2_M2/Peak_GPU_Mem_Epoch_MiB: 934.0000
2025-05-08 04:08:09,844 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:09,844 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:10,219 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 3/14 - Val Local Loss: 0.166998
2025-05-08 04:08:10,219 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:10,219 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 4680) ---
2025-05-08 04:08:10,220 - src.utils.logging_utils - INFO -   Layer_W2_M2/Val_LocalLoss_Epoch: 0.1670
2025-05-08 04:08:10,220 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:10,220 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:12,120 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:12,122 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 5070) ---
2025-05-08 04:08:12,122 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_Batch: 0.000012
2025-05-08 04:08:12,122 - src.utils.logging_utils - INFO -   Layer_W2_M2/GPU_Mem_Used_MiB_Batch: 934.0000
2025-05-08 04:08:12,122 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:12,122 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:12,123 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 4/14 - Train Loss: 0.016689, Peak Mem: 934.0 MiB
2025-05-08 04:08:12,123 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:12,123 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 5070) ---
2025-05-08 04:08:12,123 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_EpochAvg: 0.0167
2025-05-08 04:08:12,123 - src.utils.logging_utils - INFO -   Layer_W2_M2/Peak_GPU_Mem_Epoch_MiB: 934.0000
2025-05-08 04:08:12,124 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:12,124 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:12,496 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 4/14 - Val Local Loss: 0.201750
2025-05-08 04:08:12,498 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:12,498 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 5070) ---
2025-05-08 04:08:12,498 - src.utils.logging_utils - INFO -   Layer_W2_M2/Val_LocalLoss_Epoch: 0.2017
2025-05-08 04:08:12,498 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:12,498 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:14,405 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:14,406 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 5460) ---
2025-05-08 04:08:14,406 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_Batch: 0.0062
2025-05-08 04:08:14,406 - src.utils.logging_utils - INFO -   Layer_W2_M2/GPU_Mem_Used_MiB_Batch: 934.0000
2025-05-08 04:08:14,406 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:14,407 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:14,407 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 5/14 - Train Loss: 0.011690, Peak Mem: 934.0 MiB
2025-05-08 04:08:14,408 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:14,408 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 5460) ---
2025-05-08 04:08:14,408 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_EpochAvg: 0.0117
2025-05-08 04:08:14,408 - src.utils.logging_utils - INFO -   Layer_W2_M2/Peak_GPU_Mem_Epoch_MiB: 934.0000
2025-05-08 04:08:14,408 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:14,408 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:14,797 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 5/14 - Val Local Loss: 0.156669
2025-05-08 04:08:14,798 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:14,798 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 5460) ---
2025-05-08 04:08:14,798 - src.utils.logging_utils - INFO -   Layer_W2_M2/Val_LocalLoss_Epoch: 0.1567
2025-05-08 04:08:14,798 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:14,798 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:16,783 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:16,784 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 5850) ---
2025-05-08 04:08:16,784 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_Batch: 0.0558
2025-05-08 04:08:16,784 - src.utils.logging_utils - INFO -   Layer_W2_M2/GPU_Mem_Used_MiB_Batch: 934.0000
2025-05-08 04:08:16,784 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:16,784 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:16,785 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 6/14 - Train Loss: 0.011963, Peak Mem: 934.0 MiB
2025-05-08 04:08:16,785 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:16,785 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 5850) ---
2025-05-08 04:08:16,785 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_EpochAvg: 0.0120
2025-05-08 04:08:16,786 - src.utils.logging_utils - INFO -   Layer_W2_M2/Peak_GPU_Mem_Epoch_MiB: 934.0000
2025-05-08 04:08:16,786 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:16,786 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:17,161 - src.algorithms.mf - INFO - Layer_W2_M2 Epoch 6/14 - Val Local Loss: 0.176314
2025-05-08 04:08:17,162 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:17,162 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 5850) ---
2025-05-08 04:08:17,162 - src.utils.logging_utils - INFO -   Layer_W2_M2/Val_LocalLoss_Epoch: 0.1763
2025-05-08 04:08:17,162 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:17,163 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:17,163 - src.algorithms.mf - INFO - --- Layer_W2_M2: Early Stopping Triggered at Epoch 6! ---
2025-05-08 04:08:17,163 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:17,163 - src.utils.logging_utils - INFO - --- Metrics Log (Step: 5850) ---
2025-05-08 04:08:17,163 - src.utils.logging_utils - INFO -   Layer_W2_M2/Train_Loss_LayerAvg: 0.0120
2025-05-08 04:08:17,163 - src.utils.logging_utils - INFO -   Layer_W2_M2/Peak_GPU_Mem_Layer_MiB: 934.0000
2025-05-08 04:08:17,163 - src.utils.logging_utils - INFO -   Layer_W2_M2/Epochs_Trained: 6
2025-05-08 04:08:17,163 - src.utils.logging_utils - INFO - --- End Metrics Log ---
2025-05-08 04:08:17,164 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:17,175 - src.algorithms.mf - INFO - Finished all layer-wise MF training. Total Epochs Trained (Sum): 15
2025-05-08 04:08:17,176 - src.utils.logging_utils - INFO - Received Peak GPU Memory (sampled during training): 934.00 MiB
2025-05-08 04:08:17,176 - src.utils.monitoring - INFO - Stopped energy monitoring for GPU 0.
2025-05-08 04:08:17,176 - src.utils.logging_utils - INFO - Starting evaluation phase on test set...
2025-05-08 04:08:17,177 - src.algorithms.mf - INFO - Evaluating MF (MF_MLP) using a_2 and M_2.
2025-05-08 04:08:17,612 - src.algorithms.mf - INFO - MF Evaluation Results (MF_MLP, BP-style): Accuracy: 98.12%
2025-05-08 04:08:17,614 - src.utils.logging_utils - INFO - Test Set Results: Acc: 98.12%, Loss: nan
2025-05-08 04:08:17,614 - src.utils.logging_utils - INFO - Stopping CodeCarbon tracker...
2025-05-08 04:08:18,133 - src.utils.logging_utils - INFO - CodeCarbon tracker stopped. Attempting to read from: results/carbon/mf_mnist_mlp_2x1000_carbon.csv
2025-05-08 04:08:18,641 - src.utils.logging_utils - INFO - Read emissions: 0.001206 kgCO2e (1.206 gCO2e) (attempt 1)
2025-05-08 04:08:18,642 - src.utils.monitoring - INFO - Energy monitor for GPU 0 is not running.
2025-05-08 04:08:18,642 - src.utils.logging_utils - INFO - Total GPU Energy (NVML Monitor): 2095.37 J (0.5820 Wh)
2025-05-08 04:08:18,642 - src.utils.logging_utils - INFO - GPU Mem (End): 934.00 MiB Used / 40960.00 MiB Total
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO - --- Final Summary Metrics (Step: 5851) ---
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO -   final/total_run_duration_sec: 37.9413
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO -   final/peak_gpu_mem_used_mib: 934.0000
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO -   final/total_gpu_energy_joules: 2095.373856
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO -   final/total_gpu_energy_wh: 0.582048
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO -   final/training_duration_sec: 34.4974
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO -   final/Test_Accuracy: 98.1200
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO -   final/Test_Loss: nan
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO -   final/estimated_fwd_gflops: 0.0036
2025-05-08 04:08:18,643 - src.utils.logging_utils - INFO -   final/estimated_bp_update_gflops: nan
2025-05-08 04:08:18,644 - src.utils.logging_utils - INFO -   final/codecarbon_emissions_gCO2e: 1.205525
2025-05-08 04:08:18,644 - src.utils.logging_utils - INFO - --- End Final Summary ---
2025-05-08 04:08:18,644 - src.utils.logging_utils - INFO - 
2025-05-08 04:08:18,644 - src.utils.logging_utils - INFO - Total run duration: 00:00:37
2025-05-08 04:08:18,644 - src.utils.logging_utils - INFO - --> Final Calculated Emissions: 1.206 gCO2e
2025-05-08 04:08:19,605 - src.utils.logging_utils - INFO - W&B run finished.
2025-05-08 04:08:19,606 - src.utils.monitoring - INFO - NVML shut down successfully.
2025-05-08 04:08:19,691 - src.utils.logging_utils - INFO - 
--- Experiment Finished ---
2025-05-08 04:08:19,692 - src.utils.logging_utils - INFO - Results:
2025-05-08 04:08:19,692 - src.utils.logging_utils - INFO - {'codecarbon_country_iso': 'POL',
2025-05-08 04:08:19,692 - src.utils.logging_utils - INFO -  'codecarbon_csv_path': 'results/carbon/mf_mnist_mlp_2x1000_carbon.csv',
2025-05-08 04:08:19,692 - src.utils.logging_utils - INFO -  'codecarbon_emissions_gCO2e': 1.2055253951895002,
2025-05-08 04:08:19,692 - src.utils.logging_utils - INFO -  'codecarbon_enabled': True,
2025-05-08 04:08:19,692 - src.utils.logging_utils - INFO -  'codecarbon_mode': 'offline',
2025-05-08 04:08:19,692 - src.utils.logging_utils - INFO -  'estimated_bp_update_gflops': nan,
2025-05-08 04:08:19,692 - src.utils.logging_utils - INFO -  'estimated_fwd_gflops': 0.003588,
2025-05-08 04:08:19,693 - src.utils.logging_utils - INFO -  'peak_gpu_mem_used_mib': 934.0,
2025-05-08 04:08:19,693 - src.utils.logging_utils - INFO -  'test_accuracy': 98.11999999999999,
2025-05-08 04:08:19,693 - src.utils.logging_utils - INFO -  'test_loss': nan,
2025-05-08 04:08:19,693 - src.utils.logging_utils - INFO -  'total_gpu_energy_joules': 2095.373855589106,
2025-05-08 04:08:19,693 - src.utils.logging_utils - INFO -  'total_gpu_energy_wh': 0.582048293219196,
2025-05-08 04:08:19,693 - src.utils.logging_utils - INFO -  'total_run_duration_sec': 37.941346168518066,
2025-05-08 04:08:19,693 - src.utils.logging_utils - INFO -  'training_duration_sec': 34.497392416000366}
2025-05-08 04:08:19,693 - src.utils.logging_utils - INFO - 
--- Experiment Finished Successfully ---
Deactivating virtual environment...
#####################################################################
Job finished with exit code 0 at Thu May  8 04:08:21 CEST 2025
#####################################################################
